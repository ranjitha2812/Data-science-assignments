{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb610f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13feb048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp39-cp39-win_amd64.whl (444.0 MB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.1-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.33.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=56065444eb1b89b97396b3a25343ab7fc60a9f51d11c0cefa4eac4038be49cca\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\b6\\0d\\90\\0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.1.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-preprocessing-1.1.2 libclang-14.0.1 oauthlib-3.2.0 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7786d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f156ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"gas_turbines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb43709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2378dacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.00000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.764381</td>\n",
       "      <td>1013.19924</td>\n",
       "      <td>79.124174</td>\n",
       "      <td>4.200294</td>\n",
       "      <td>25.419061</td>\n",
       "      <td>1083.798770</td>\n",
       "      <td>545.396183</td>\n",
       "      <td>134.188464</td>\n",
       "      <td>12.102353</td>\n",
       "      <td>1.972499</td>\n",
       "      <td>68.190934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.574323</td>\n",
       "      <td>6.41076</td>\n",
       "      <td>13.793439</td>\n",
       "      <td>0.760197</td>\n",
       "      <td>4.173916</td>\n",
       "      <td>16.527806</td>\n",
       "      <td>7.866803</td>\n",
       "      <td>15.829717</td>\n",
       "      <td>1.103196</td>\n",
       "      <td>2.222206</td>\n",
       "      <td>10.470586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.522300</td>\n",
       "      <td>985.85000</td>\n",
       "      <td>30.344000</td>\n",
       "      <td>2.087400</td>\n",
       "      <td>17.878000</td>\n",
       "      <td>1000.800000</td>\n",
       "      <td>512.450000</td>\n",
       "      <td>100.170000</td>\n",
       "      <td>9.904400</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>27.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.408000</td>\n",
       "      <td>1008.90000</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>3.723900</td>\n",
       "      <td>23.294000</td>\n",
       "      <td>1079.600000</td>\n",
       "      <td>542.170000</td>\n",
       "      <td>127.985000</td>\n",
       "      <td>11.622000</td>\n",
       "      <td>0.858055</td>\n",
       "      <td>61.303500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.186000</td>\n",
       "      <td>1012.80000</td>\n",
       "      <td>82.266000</td>\n",
       "      <td>4.186200</td>\n",
       "      <td>25.082000</td>\n",
       "      <td>1088.700000</td>\n",
       "      <td>549.890000</td>\n",
       "      <td>133.780000</td>\n",
       "      <td>12.025000</td>\n",
       "      <td>1.390200</td>\n",
       "      <td>66.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.862500</td>\n",
       "      <td>1016.90000</td>\n",
       "      <td>90.043500</td>\n",
       "      <td>4.550900</td>\n",
       "      <td>27.184000</td>\n",
       "      <td>1096.000000</td>\n",
       "      <td>550.060000</td>\n",
       "      <td>140.895000</td>\n",
       "      <td>12.578000</td>\n",
       "      <td>2.160400</td>\n",
       "      <td>73.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.929000</td>\n",
       "      <td>1034.20000</td>\n",
       "      <td>100.200000</td>\n",
       "      <td>7.610600</td>\n",
       "      <td>37.402000</td>\n",
       "      <td>1100.800000</td>\n",
       "      <td>550.610000</td>\n",
       "      <td>174.610000</td>\n",
       "      <td>15.081000</td>\n",
       "      <td>44.103000</td>\n",
       "      <td>119.890000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AT           AP            AH          AFDP          GTEP  \\\n",
       "count  15039.000000  15039.00000  15039.000000  15039.000000  15039.000000   \n",
       "mean      17.764381   1013.19924     79.124174      4.200294     25.419061   \n",
       "std        7.574323      6.41076     13.793439      0.760197      4.173916   \n",
       "min        0.522300    985.85000     30.344000      2.087400     17.878000   \n",
       "25%       11.408000   1008.90000     69.750000      3.723900     23.294000   \n",
       "50%       18.186000   1012.80000     82.266000      4.186200     25.082000   \n",
       "75%       23.862500   1016.90000     90.043500      4.550900     27.184000   \n",
       "max       34.929000   1034.20000    100.200000      7.610600     37.402000   \n",
       "\n",
       "                TIT           TAT           TEY           CDP            CO  \\\n",
       "count  15039.000000  15039.000000  15039.000000  15039.000000  15039.000000   \n",
       "mean    1083.798770    545.396183    134.188464     12.102353      1.972499   \n",
       "std       16.527806      7.866803     15.829717      1.103196      2.222206   \n",
       "min     1000.800000    512.450000    100.170000      9.904400      0.000388   \n",
       "25%     1079.600000    542.170000    127.985000     11.622000      0.858055   \n",
       "50%     1088.700000    549.890000    133.780000     12.025000      1.390200   \n",
       "75%     1096.000000    550.060000    140.895000     12.578000      2.160400   \n",
       "max     1100.800000    550.610000    174.610000     15.081000     44.103000   \n",
       "\n",
       "                NOX  \n",
       "count  15039.000000  \n",
       "mean      68.190934  \n",
       "std       10.470586  \n",
       "min       27.765000  \n",
       "25%       61.303500  \n",
       "50%       66.601000  \n",
       "75%       73.935500  \n",
       "max      119.890000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98d1325d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc4b24db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT      0\n",
       "AP      0\n",
       "AH      0\n",
       "AFDP    0\n",
       "GTEP    0\n",
       "TIT     0\n",
       "TAT     0\n",
       "TEY     0\n",
       "CDP     0\n",
       "CO      0\n",
       "NOX     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5fc3cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='TEY'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data['TEY'], color = 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d42864bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:,['AT', 'AP', 'AH', 'AFDP', 'GTEP', 'TIT', 'TAT', 'CDP', 'CO','NOX']]\n",
    "y= data.loc[:,['TEY']]\n",
    "scaled = StandardScaler()\n",
    "X = scaled.fit_transform(X)\n",
    "y = scaled.fit_transform(y)\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=10, activation='tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74b632b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12916\\1991303876.py:6: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=50, batch_size=100, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.19 (0.15) MSE\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer,Dense\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=50, batch_size=100, verbose=False)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, X, y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87815d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.3524047, -1.3372881, -1.3102084, ..., -1.3816996, -1.3048644,\n",
       "       -1.2472296], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X, y)\n",
    "prediction = estimator.predict(X)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c059630f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0884278 ,  1.5033231 ,  1.7096936 , ...,  0.05729017,\n",
       "        0.8699917 , -1.2325134 ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)\n",
    "estimator.fit(X_train, y_train)\n",
    "prediction = estimator.predict(X_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adec97b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82623246, -0.43954308, -0.25924569, ...,  0.10039242,\n",
       "        -0.3796304 , -0.69217007],\n",
       "       [ 0.35282087,  0.23279782,  0.80230139, ..., -1.18541222,\n",
       "         0.39149515, -1.09475442],\n",
       "       [ 0.32839008, -0.07135639,  0.25312287, ...,  0.01665304,\n",
       "        -0.00296896, -0.31891741],\n",
       "       ...,\n",
       "       [-0.74071701,  0.37687087,  0.43427425, ...,  1.77157829,\n",
       "        -1.00127821, -0.4818816 ],\n",
       "       [-0.49965786, -0.39151873,  0.64680105, ..., -0.26517949,\n",
       "        -0.48137538,  0.12808615],\n",
       "       [ 0.13151427,  0.32884652,  0.98830762, ..., -1.40331469,\n",
       "         0.13152215, -0.64456466]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns = ['TEY'], axis = 1) \n",
    "y = data.iloc[:,7]\n",
    "from sklearn.preprocessing import scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)\n",
    "X_train_scaled = scale(X_train)\n",
    "X_test_scaled = scale(X_test)\n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b81119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "input_size = len(X.columns)\n",
    "output_size = 1\n",
    "hidden_layer_size = 50\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                                \n",
    "                               tf.keras.layers.Dense(hidden_layer_size, input_dim = input_size, activation = 'relu'),\n",
    "                               tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "                               tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "                               tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),     \n",
    "                               tf.keras.layers.Dense(output_size)\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9620a26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "381/381 - 1s - loss: 2867.7725 - mean_squared_error: 2867.7725 - val_loss: 187.5864 - val_mean_squared_error: 187.5864 - 992ms/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "381/381 - 0s - loss: 110.1595 - mean_squared_error: 110.1595 - val_loss: 78.2724 - val_mean_squared_error: 78.2724 - 361ms/epoch - 948us/step\n",
      "Epoch 3/100\n",
      "381/381 - 0s - loss: 47.9547 - mean_squared_error: 47.9547 - val_loss: 33.0925 - val_mean_squared_error: 33.0925 - 354ms/epoch - 930us/step\n",
      "Epoch 4/100\n",
      "381/381 - 0s - loss: 21.4884 - mean_squared_error: 21.4884 - val_loss: 13.6126 - val_mean_squared_error: 13.6126 - 377ms/epoch - 989us/step\n",
      "Epoch 5/100\n",
      "381/381 - 0s - loss: 10.6448 - mean_squared_error: 10.6448 - val_loss: 7.6110 - val_mean_squared_error: 7.6110 - 349ms/epoch - 916us/step\n",
      "Epoch 6/100\n",
      "381/381 - 0s - loss: 5.9248 - mean_squared_error: 5.9248 - val_loss: 4.2812 - val_mean_squared_error: 4.2812 - 347ms/epoch - 911us/step\n",
      "Epoch 7/100\n",
      "381/381 - 0s - loss: 3.6176 - mean_squared_error: 3.6176 - val_loss: 3.3460 - val_mean_squared_error: 3.3460 - 356ms/epoch - 935us/step\n",
      "Epoch 8/100\n",
      "381/381 - 0s - loss: 2.5909 - mean_squared_error: 2.5909 - val_loss: 1.8960 - val_mean_squared_error: 1.8960 - 343ms/epoch - 901us/step\n",
      "Epoch 9/100\n",
      "381/381 - 0s - loss: 1.7976 - mean_squared_error: 1.7976 - val_loss: 1.6828 - val_mean_squared_error: 1.6828 - 348ms/epoch - 912us/step\n",
      "Epoch 10/100\n",
      "381/381 - 0s - loss: 1.5636 - mean_squared_error: 1.5636 - val_loss: 1.5458 - val_mean_squared_error: 1.5458 - 366ms/epoch - 960us/step\n",
      "Epoch 11/100\n",
      "381/381 - 0s - loss: 1.2618 - mean_squared_error: 1.2618 - val_loss: 1.0018 - val_mean_squared_error: 1.0018 - 357ms/epoch - 936us/step\n",
      "Epoch 12/100\n",
      "381/381 - 0s - loss: 1.0254 - mean_squared_error: 1.0254 - val_loss: 1.3461 - val_mean_squared_error: 1.3461 - 356ms/epoch - 935us/step\n",
      "Epoch 13/100\n",
      "381/381 - 0s - loss: 1.0170 - mean_squared_error: 1.0170 - val_loss: 0.9543 - val_mean_squared_error: 0.9543 - 357ms/epoch - 936us/step\n",
      "Epoch 14/100\n",
      "381/381 - 0s - loss: 0.9853 - mean_squared_error: 0.9853 - val_loss: 0.7003 - val_mean_squared_error: 0.7003 - 350ms/epoch - 919us/step\n",
      "Epoch 15/100\n",
      "381/381 - 0s - loss: 0.8704 - mean_squared_error: 0.8704 - val_loss: 0.8220 - val_mean_squared_error: 0.8220 - 337ms/epoch - 885us/step\n",
      "Epoch 16/100\n",
      "381/381 - 0s - loss: 0.8316 - mean_squared_error: 0.8316 - val_loss: 1.1658 - val_mean_squared_error: 1.1658 - 349ms/epoch - 916us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x298668e1d60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.03)\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['MeanSquaredError'])\n",
    "num_epochs = 100\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience = 2)\n",
    "model.fit(X_train_scaled, y_train, callbacks = early_stopping, validation_split = 0.1, epochs = num_epochs, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9324b2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 917us/step - loss: 0.9334 - mean_squared_error: 0.9334\n"
     ]
    }
   ],
   "source": [
    "test_loss, mean_squared_error = model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "492b0458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x298629785b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict_on_batch(X_test_scaled)\n",
    "plt.scatter(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd6d4d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>% Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134.46</td>\n",
       "      <td>134.024689</td>\n",
       "      <td>0.323748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111.88</td>\n",
       "      <td>111.408508</td>\n",
       "      <td>0.421426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.72</td>\n",
       "      <td>133.663910</td>\n",
       "      <td>0.041946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>133.79</td>\n",
       "      <td>133.206116</td>\n",
       "      <td>0.436418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110.77</td>\n",
       "      <td>109.699493</td>\n",
       "      <td>0.966423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>132.85</td>\n",
       "      <td>132.605225</td>\n",
       "      <td>0.184249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>125.07</td>\n",
       "      <td>126.389839</td>\n",
       "      <td>1.055280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>160.95</td>\n",
       "      <td>160.364532</td>\n",
       "      <td>0.363757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>133.12</td>\n",
       "      <td>132.347046</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>111.79</td>\n",
       "      <td>110.051468</td>\n",
       "      <td>1.555177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1504 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual   Predicted   % Error\n",
       "0     134.46  134.024689  0.323748\n",
       "1     111.88  111.408508  0.421426\n",
       "2     133.72  133.663910  0.041946\n",
       "3     133.79  133.206116  0.436418\n",
       "4     110.77  109.699493  0.966423\n",
       "...      ...         ...       ...\n",
       "1499  132.85  132.605225  0.184249\n",
       "1500  125.07  126.389839  1.055280\n",
       "1501  160.95  160.364532  0.363757\n",
       "1502  133.12  132.347046  0.580645\n",
       "1503  111.79  110.051468  1.555177\n",
       "\n",
       "[1504 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame()\n",
    "predictions_df['Actual'] = y_test\n",
    "predictions_df['Predicted'] = predictions\n",
    "predictions_df['% Error'] = abs(predictions_df['Actual'] - predictions_df['Predicted'])/predictions_df['Actual']*100\n",
    "predictions_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b03251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
